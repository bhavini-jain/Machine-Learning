{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessment 2 - Building LR Model for Delhi Temprature Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_utc</th>\n",
       "      <th>_conds</th>\n",
       "      <th>_dewptm</th>\n",
       "      <th>_fog</th>\n",
       "      <th>_hail</th>\n",
       "      <th>_heatindexm</th>\n",
       "      <th>_hum</th>\n",
       "      <th>_precipm</th>\n",
       "      <th>_pressurem</th>\n",
       "      <th>_rain</th>\n",
       "      <th>_snow</th>\n",
       "      <th>_tempm</th>\n",
       "      <th>_thunder</th>\n",
       "      <th>_tornado</th>\n",
       "      <th>_vism</th>\n",
       "      <th>_wdird</th>\n",
       "      <th>_wdire</th>\n",
       "      <th>_wgustm</th>\n",
       "      <th>_windchillm</th>\n",
       "      <th>_wspdm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19961101-11:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>West</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19961101-12:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19961101-13:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9999.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19961101-14:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19961101-16:00</td>\n",
       "      <td>Smoke</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1011.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>North</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100985</th>\n",
       "      <td>20170424-06:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100986</th>\n",
       "      <td>20170424-09:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100987</th>\n",
       "      <td>20170424-12:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>West</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100988</th>\n",
       "      <td>20170424-15:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100989</th>\n",
       "      <td>20170424-18:00</td>\n",
       "      <td>Haze</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100990 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          datetime_utc  _conds   _dewptm   _fog   _hail   _heatindexm   _hum  \\\n",
       "0       19961101-11:00   Smoke       9.0      0       0           NaN   27.0   \n",
       "1       19961101-12:00   Smoke      10.0      0       0           NaN   32.0   \n",
       "2       19961101-13:00   Smoke      11.0      0       0           NaN   44.0   \n",
       "3       19961101-14:00   Smoke      10.0      0       0           NaN   41.0   \n",
       "4       19961101-16:00   Smoke      11.0      0       0           NaN   47.0   \n",
       "...                ...     ...       ...    ...     ...           ...    ...   \n",
       "100985  20170424-06:00    Haze      17.0      0       0           NaN   25.0   \n",
       "100986  20170424-09:00    Haze      14.0      0       0           NaN   16.0   \n",
       "100987  20170424-12:00    Haze      12.0      0       0           NaN   14.0   \n",
       "100988  20170424-15:00    Haze      15.0      0       0           NaN   27.0   \n",
       "100989  20170424-18:00    Haze      15.0      0       0           NaN   30.0   \n",
       "\n",
       "         _precipm   _pressurem   _rain   _snow   _tempm   _thunder   _tornado  \\\n",
       "0             NaN       1010.0       0       0     30.0          0          0   \n",
       "1             NaN      -9999.0       0       0     28.0          0          0   \n",
       "2             NaN      -9999.0       0       0     24.0          0          0   \n",
       "3             NaN       1010.0       0       0     24.0          0          0   \n",
       "4             NaN       1011.0       0       0     23.0          0          0   \n",
       "...           ...          ...     ...     ...      ...        ...        ...   \n",
       "100985        NaN       1005.0       0       0     34.0          0          0   \n",
       "100986        NaN       1003.0       0       0     38.0          0          0   \n",
       "100987        NaN       1002.0       0       0     36.0          0          0   \n",
       "100988        NaN       1004.0       0       0     32.0          0          0   \n",
       "100989        NaN       1005.0       0       0     30.0          0          0   \n",
       "\n",
       "         _vism   _wdird  _wdire   _wgustm   _windchillm   _wspdm  \n",
       "0          5.0    280.0    West       NaN           NaN      7.4  \n",
       "1          NaN      0.0   North       NaN           NaN      NaN  \n",
       "2          NaN      0.0   North       NaN           NaN      NaN  \n",
       "3          2.0      0.0   North       NaN           NaN      NaN  \n",
       "4          1.2      0.0   North       NaN           NaN      0.0  \n",
       "...        ...      ...     ...       ...           ...      ...  \n",
       "100985     4.0    320.0      NW       NaN           NaN     11.1  \n",
       "100986     4.0    320.0      NW       NaN           NaN     22.2  \n",
       "100987     4.0    270.0    West       NaN           NaN     18.5  \n",
       "100988     2.0    320.0      NW       NaN           NaN      3.7  \n",
       "100989     2.0    320.0      NW       NaN           NaN      3.7  \n",
       "\n",
       "[100990 rows x 20 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('F:\\Dataset\\Delhi Temerature.csv')          ## reading dataset presnet in local device\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows and column of our main dataset--> (100990, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows and column of our main dataset-->\",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## droping null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Droping those columns have large amout of null values\n",
      "\n",
      " Index([' _heatindexm', ' _precipm', ' _wgustm', ' _windchillm'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "null_data = df.isnull().sum()/df.shape[0]*100\n",
    "null_columns = null_data[null_data>20].keys()        # fetching columns having more than 20% of missing data\n",
    "df = df.drop(\"datetime_utc\",axis=1)                  # no need of this column\n",
    "print(\"Droping those columns have large amout of null values\\n\\n\",null_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows and column of our main dataset after removing null columns--> (100990, 15)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=null_columns)                         #droping columns \n",
    "print(\"Total rows and column of our main dataset after removing null columns-->\",df.shape)              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding missing numerical null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null data present in our Numerial dataset 23824\n"
     ]
    }
   ],
   "source": [
    "X_num = df.select_dtypes(include=[\"int64\",\"float64\"])                                         # select numerical data type\n",
    "print(\"Number of null data present in our Numerial dataset\",X_num.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical data having null values\n",
      "\n",
      " [' _dewptm', ' _hum', ' _pressurem', ' _tempm', ' _vism', ' _wdird', ' _wspdm']\n"
     ]
    }
   ],
   "source": [
    "num_nn = [var for var in X_num.columns if X_num[var].isnull().sum()>0]      #finding numerical columns having missing values\n",
    "print(\"Numerical data having null values\\n\\n\",num_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finding missing object null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character data having null values\n",
      "\n",
      " [' _conds', ' _wdire']\n"
     ]
    }
   ],
   "source": [
    "X_char = df.select_dtypes(include=[\"object\"])                                # selecting stirng data\n",
    "char_nn = [var for var in X_char.columns if X_char[var].isnull().sum()>0]\n",
    "print(\"Character data having null values\\n\\n\",char_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filling values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nn = [' _dewptm', ' _hum', ' _pressurem', ' _vism', ' _wdird', ' _wspdm']      #missing numerical data col\n",
    "char_nn = [' _conds', ' _wdire']                                                   # missing char data col\n",
    "\n",
    "#creating two pipeline one is median( for numerical missing data) and other is mode(for string missing data)\n",
    "meadian_impute = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"median\"))])   \n",
    "mode_impute = Pipeline(steps=[(\"imputer\",SimpleImputer(strategy=\"most_frequent\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer(transformers=[(\"median\",mean_impute,num_nn),          #applying strategy\n",
    "                                             (\"mode\",mode_impute,char_nn)\n",
    "                                             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('median',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='mean',\n",
       "                                                                verbose=0))],\n",
       "                                          verbose=False),\n",
       "                                 [' _dewptm', ' _hum', ' _pressurem', ' _vism',\n",
       "                                  ' _wdird', ' _wspdm']),\n",
       "                                ('mode',\n",
       "                                 Pipeline(memory=None,\n",
       "                                          steps=[('imputer',\n",
       "                                                  SimpleImputer(add_indicator=False,\n",
       "                                                                copy=True,\n",
       "                                                                fill_value=None,\n",
       "                                                                missing_values=nan,\n",
       "                                                                strategy='most_frequent',\n",
       "                                                                verbose=0))],\n",
       "                                          verbose=False),\n",
       "                                 [' _conds', ' _wdire'])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(df)                                                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " _conds          0\n",
       " _dewptm         0\n",
       " _fog            0\n",
       " _hail           0\n",
       " _hum            0\n",
       " _pressurem      0\n",
       " _rain           0\n",
       " _snow           0\n",
       " _tempm        673\n",
       " _thunder        0\n",
       " _tornado        0\n",
       " _vism           0\n",
       " _wdird          0\n",
       " _wdire          0\n",
       " _wspdm          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#applying these changes in our main dataset(filling missing values)\n",
    "\n",
    "updated_values = transformer.transform(df)\n",
    "update_df = pd.DataFrame(updated_values,columns=num_nn+char_nn)                     \n",
    "df.update(update_df)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(subset=[\" _tempm\"])            #droping N/A values form this column because it has 637 null values\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total null values in our dataset --> 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total null values in our dataset -->\",df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dividing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\" _tempm\"])                        #we have to predict the _tempm column by Linear regression \n",
    "y = df[\" _tempm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "end = np.array([enc.fit_transform(X[var]) for var in char_nn])\n",
    "X[' _conds'] = end[0]                                                             \n",
    "X[' _wdire'] = end[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)                             #applying standard scaler scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting dataset in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test, Y_train,Y_test = train_test_split(X,y,test_size=.3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preparing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model = model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.0\n"
     ]
    }
   ],
   "source": [
    "print(round(model.score(X_test,Y_test)*100))                  #accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.09805086925765"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(Y_test,Y_pred)\n",
    "mse                                                        #mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.469423185534964"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse=np.sqrt(mse)\n",
    "rmse                                                         #root mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
